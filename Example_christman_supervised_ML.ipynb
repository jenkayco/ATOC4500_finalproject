{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7ee120c",
      "metadata": {
        "id": "d7ee120c"
      },
      "outputs": [],
      "source": [
        "### supervised machine learning\n",
        "### Coded by Eleanor Middlemas (Jupiter, formerly University of Colorado)\n",
        "### Additional code/commenting from Jennifer Kay (University of Colorado) \n",
        "### Last updated March 31, 2022\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import time\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### upload file christman_2016.csv\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))#"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "xlOs7rl3_9Tf",
        "outputId": "17a05457-d64d-4ee0-86bc-77544119a04d"
      },
      "id": "xlOs7rl3_9Tf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7b13e13b-b40c-4d00-b458-d9f29be5e1ec\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7b13e13b-b40c-4d00-b458-d9f29be5e1ec\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving christman_2016.csv to christman_2016.csv\n",
            "User uploaded file \"christman_2016.csv\" with length 510492 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11e6df61",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "11e6df61",
        "outputId": "711c4259-afc3-4c37-b7fe-b39b8ea2df8a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        day      hour  temp_F    RH  dewtemp_F  wind_mph  wind_dir  windgust  \\\n",
              "0     42370  0.000000     7.0  72.2       -0.1       1.2       234       3.9   \n",
              "1     42370  0.041667     5.4  74.3       -1.0       3.4       299       7.1   \n",
              "2     42370  0.083333     6.4  73.8       -0.2       2.8       200       7.0   \n",
              "3     42370  0.125000     3.0  73.5       -3.6       2.9       309       6.1   \n",
              "4     42370  0.166667     3.7  76.9       -1.9       3.1       346       5.3   \n",
              "...     ...       ...     ...   ...        ...       ...       ...       ...   \n",
              "8779  42735  0.791667    22.3  74.3       15.4       0.9       221       3.3   \n",
              "8780  42735  0.833333    20.3  80.4       15.3       0.6       279       2.9   \n",
              "8781  42735  0.875000    19.9  81.1       15.1       0.5       197       2.5   \n",
              "8782  42735  0.916667    17.8  82.8       13.5       2.0       353       4.8   \n",
              "8783  42735  0.958333    16.3  84.1       12.4       1.0       191       4.9   \n",
              "\n",
              "      windgust_dir  pres_Hg  SOLIN_Wm2  Prec_inches  \n",
              "0              224   851.30        0.0          0.0  \n",
              "1              302   850.82        0.0          0.0  \n",
              "2              301   849.83        0.0          0.0  \n",
              "3              349   850.69        0.0          0.0  \n",
              "4              255   848.24        0.0          0.0  \n",
              "...            ...      ...        ...          ...  \n",
              "8779           202   833.32        0.0          0.0  \n",
              "8780           279   833.45        0.1          0.0  \n",
              "8781           279   833.01        0.1          0.0  \n",
              "8782           352   832.78        0.1          0.0  \n",
              "8783           353   832.62        0.0          0.0  \n",
              "\n",
              "[8784 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f748891c-51a5-43b8-a5ff-96d5655cf05a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>day</th>\n",
              "      <th>hour</th>\n",
              "      <th>temp_F</th>\n",
              "      <th>RH</th>\n",
              "      <th>dewtemp_F</th>\n",
              "      <th>wind_mph</th>\n",
              "      <th>wind_dir</th>\n",
              "      <th>windgust</th>\n",
              "      <th>windgust_dir</th>\n",
              "      <th>pres_Hg</th>\n",
              "      <th>SOLIN_Wm2</th>\n",
              "      <th>Prec_inches</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>42370</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.0</td>\n",
              "      <td>72.2</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>1.2</td>\n",
              "      <td>234</td>\n",
              "      <td>3.9</td>\n",
              "      <td>224</td>\n",
              "      <td>851.30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>42370</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>5.4</td>\n",
              "      <td>74.3</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>299</td>\n",
              "      <td>7.1</td>\n",
              "      <td>302</td>\n",
              "      <td>850.82</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>42370</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>6.4</td>\n",
              "      <td>73.8</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>2.8</td>\n",
              "      <td>200</td>\n",
              "      <td>7.0</td>\n",
              "      <td>301</td>\n",
              "      <td>849.83</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>42370</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>73.5</td>\n",
              "      <td>-3.6</td>\n",
              "      <td>2.9</td>\n",
              "      <td>309</td>\n",
              "      <td>6.1</td>\n",
              "      <td>349</td>\n",
              "      <td>850.69</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>42370</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>3.7</td>\n",
              "      <td>76.9</td>\n",
              "      <td>-1.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>346</td>\n",
              "      <td>5.3</td>\n",
              "      <td>255</td>\n",
              "      <td>848.24</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8779</th>\n",
              "      <td>42735</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>22.3</td>\n",
              "      <td>74.3</td>\n",
              "      <td>15.4</td>\n",
              "      <td>0.9</td>\n",
              "      <td>221</td>\n",
              "      <td>3.3</td>\n",
              "      <td>202</td>\n",
              "      <td>833.32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8780</th>\n",
              "      <td>42735</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>20.3</td>\n",
              "      <td>80.4</td>\n",
              "      <td>15.3</td>\n",
              "      <td>0.6</td>\n",
              "      <td>279</td>\n",
              "      <td>2.9</td>\n",
              "      <td>279</td>\n",
              "      <td>833.45</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8781</th>\n",
              "      <td>42735</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>19.9</td>\n",
              "      <td>81.1</td>\n",
              "      <td>15.1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>197</td>\n",
              "      <td>2.5</td>\n",
              "      <td>279</td>\n",
              "      <td>833.01</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8782</th>\n",
              "      <td>42735</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>17.8</td>\n",
              "      <td>82.8</td>\n",
              "      <td>13.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>353</td>\n",
              "      <td>4.8</td>\n",
              "      <td>352</td>\n",
              "      <td>832.78</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8783</th>\n",
              "      <td>42735</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>16.3</td>\n",
              "      <td>84.1</td>\n",
              "      <td>12.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>191</td>\n",
              "      <td>4.9</td>\n",
              "      <td>353</td>\n",
              "      <td>832.62</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8784 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f748891c-51a5-43b8-a5ff-96d5655cf05a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f748891c-51a5-43b8-a5ff-96d5655cf05a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f748891c-51a5-43b8-a5ff-96d5655cf05a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# read in the data\n",
        "df = pd.read_csv(\"christman_2016.csv\")\n",
        "# preview data (also through df.head() & df.tail())\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aacc35d3",
      "metadata": {
        "id": "aacc35d3"
      },
      "source": [
        "**Deal with the time dimension**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e2b3f70",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e2b3f70",
        "outputId": "575f1202-7564-4432-b79b-5b6e90ba6fe0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "366"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df.day.nunique() ## How many days are in this dataset?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "223ec84b",
      "metadata": {
        "id": "223ec84b"
      },
      "outputs": [],
      "source": [
        "##Optional: transform the day column into a readable date. Run this ONCE.\n",
        "df['day'] = [datetime.date.fromordinal(day+693594) for day in df['day']]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b9ff5d4",
      "metadata": {
        "id": "2b9ff5d4"
      },
      "source": [
        "**Q1. What exactly are you trying to predict?**\n",
        "\n",
        "First, split data into predictor & predictands. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92dd2ad5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92dd2ad5",
        "outputId": "709d720f-e3e4-4098-b4f0-6238853d7146"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['day', 'hour', 'temp_F', 'RH', 'dewtemp_F', 'wind_mph', 'wind_dir',\n",
            "       'windgust', 'windgust_dir', 'pres_Hg', 'SOLIN_Wm2', 'Prec_inches'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "##I'm going to create (or \"engineer\") a new feature that indicates whether precipitation occurred. \n",
        "## Perform this step ONCE.\n",
        "\n",
        "print(df.columns) # print so that you can see what is the variable called that indicates precipitation amount?\n",
        "\n",
        "df['prec_occur'] = np.array(df.Prec_inches!=0).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "482a82c6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "482a82c6",
        "outputId": "6b7280e2-6040-47e1-cabb-2e5ce9be5411"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      temp_F    RH  dewtemp_F  wind_mph  wind_dir  windgust  windgust_dir  \\\n",
              "0        7.0  72.2       -0.1       1.2       234       3.9           224   \n",
              "1        5.4  74.3       -1.0       3.4       299       7.1           302   \n",
              "2        6.4  73.8       -0.2       2.8       200       7.0           301   \n",
              "3        3.0  73.5       -3.6       2.9       309       6.1           349   \n",
              "4        3.7  76.9       -1.9       3.1       346       5.3           255   \n",
              "...      ...   ...        ...       ...       ...       ...           ...   \n",
              "8779    22.3  74.3       15.4       0.9       221       3.3           202   \n",
              "8780    20.3  80.4       15.3       0.6       279       2.9           279   \n",
              "8781    19.9  81.1       15.1       0.5       197       2.5           279   \n",
              "8782    17.8  82.8       13.5       2.0       353       4.8           352   \n",
              "8783    16.3  84.1       12.4       1.0       191       4.9           353   \n",
              "\n",
              "      pres_Hg  SOLIN_Wm2  prec_occur  \n",
              "0      851.30        0.0           0  \n",
              "1      850.82        0.0           0  \n",
              "2      849.83        0.0           0  \n",
              "3      850.69        0.0           0  \n",
              "4      848.24        0.0           0  \n",
              "...       ...        ...         ...  \n",
              "8779   833.32        0.0           0  \n",
              "8780   833.45        0.1           0  \n",
              "8781   833.01        0.1           0  \n",
              "8782   832.78        0.1           0  \n",
              "8783   832.62        0.0           0  \n",
              "\n",
              "[8784 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-63b4fa05-5dd5-4e1f-83ba-fc4f79447374\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>temp_F</th>\n",
              "      <th>RH</th>\n",
              "      <th>dewtemp_F</th>\n",
              "      <th>wind_mph</th>\n",
              "      <th>wind_dir</th>\n",
              "      <th>windgust</th>\n",
              "      <th>windgust_dir</th>\n",
              "      <th>pres_Hg</th>\n",
              "      <th>SOLIN_Wm2</th>\n",
              "      <th>prec_occur</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.0</td>\n",
              "      <td>72.2</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>1.2</td>\n",
              "      <td>234</td>\n",
              "      <td>3.9</td>\n",
              "      <td>224</td>\n",
              "      <td>851.30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.4</td>\n",
              "      <td>74.3</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>299</td>\n",
              "      <td>7.1</td>\n",
              "      <td>302</td>\n",
              "      <td>850.82</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.4</td>\n",
              "      <td>73.8</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>2.8</td>\n",
              "      <td>200</td>\n",
              "      <td>7.0</td>\n",
              "      <td>301</td>\n",
              "      <td>849.83</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>73.5</td>\n",
              "      <td>-3.6</td>\n",
              "      <td>2.9</td>\n",
              "      <td>309</td>\n",
              "      <td>6.1</td>\n",
              "      <td>349</td>\n",
              "      <td>850.69</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.7</td>\n",
              "      <td>76.9</td>\n",
              "      <td>-1.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>346</td>\n",
              "      <td>5.3</td>\n",
              "      <td>255</td>\n",
              "      <td>848.24</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8779</th>\n",
              "      <td>22.3</td>\n",
              "      <td>74.3</td>\n",
              "      <td>15.4</td>\n",
              "      <td>0.9</td>\n",
              "      <td>221</td>\n",
              "      <td>3.3</td>\n",
              "      <td>202</td>\n",
              "      <td>833.32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8780</th>\n",
              "      <td>20.3</td>\n",
              "      <td>80.4</td>\n",
              "      <td>15.3</td>\n",
              "      <td>0.6</td>\n",
              "      <td>279</td>\n",
              "      <td>2.9</td>\n",
              "      <td>279</td>\n",
              "      <td>833.45</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8781</th>\n",
              "      <td>19.9</td>\n",
              "      <td>81.1</td>\n",
              "      <td>15.1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>197</td>\n",
              "      <td>2.5</td>\n",
              "      <td>279</td>\n",
              "      <td>833.01</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8782</th>\n",
              "      <td>17.8</td>\n",
              "      <td>82.8</td>\n",
              "      <td>13.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>353</td>\n",
              "      <td>4.8</td>\n",
              "      <td>352</td>\n",
              "      <td>832.78</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8783</th>\n",
              "      <td>16.3</td>\n",
              "      <td>84.1</td>\n",
              "      <td>12.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>191</td>\n",
              "      <td>4.9</td>\n",
              "      <td>353</td>\n",
              "      <td>832.62</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8784 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63b4fa05-5dd5-4e1f-83ba-fc4f79447374')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-63b4fa05-5dd5-4e1f-83ba-fc4f79447374 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-63b4fa05-5dd5-4e1f-83ba-fc4f79447374');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "#Next, select the data that will be predictors.\n",
        "predictors = df.copy(deep=True)  # here, we use \"deep = True\" so that changes to predictors won't be made to the df.\n",
        "\n",
        "#Next, we drop some variables that shouldn't be used to predict whether or not there is rain.\n",
        "predictors = df.drop(['day','hour','Prec_inches'],axis=1) \n",
        "predictors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8ff62ec",
      "metadata": {
        "id": "c8ff62ec"
      },
      "outputs": [],
      "source": [
        "## Great, that worked. Now I will assign everything but \"prec\" to be the predictor array \"x\", \n",
        "## and prec will be the predictand vector \"y\".\n",
        "\n",
        "x = predictors.drop('prec_occur',axis=1)\n",
        "y = predictors.prec_occur"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "666a35b2",
      "metadata": {
        "id": "666a35b2"
      },
      "source": [
        "**Q2 & Q3 do not need to be addressed in our dataset.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e53cb777",
      "metadata": {
        "id": "e53cb777"
      },
      "source": [
        "**Q4. How will you validate your model?**\n",
        "\n",
        "perform a test-train split to validate our trained model.\n",
        "This step must be performed before each time the model is trained to ensure we are not \n",
        "baking in any bias among the models we train. That also means the following two steps must \n",
        "also be performed prior to training each model as well. For this reason, I wrote functions to call \n",
        "easily before each model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d480b0fc",
      "metadata": {
        "id": "d480b0fc"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from random import randint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74313cb6",
      "metadata": {
        "id": "74313cb6"
      },
      "outputs": [],
      "source": [
        "def define_holdout_data(x, y, verbose):\n",
        "    \"\"\"Perform a 80/20 test-train split (80% of data is training, 20% is testing). Split is randomized with each call.\"\"\"\n",
        "    random_state = randint(0,1000)\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=random_state)\n",
        "    if verbose==True:\n",
        "        print(\"Prior to scaling and rebalacing...\")\n",
        "        print(\"Shape of training predictors: \"+str(np.shape(x_train)))\n",
        "        print(\"Shape of testing predictors: \"+str(np.shape(x_test)))\n",
        "        print(\"Shape of training predictands: \"+str(np.shape(y_train)))\n",
        "        print(\"Shape of testing predictands: \"+str(np.shape(y_test)))\n",
        "        print(\" \")\n",
        "    return x_train, x_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a2bb2c7",
      "metadata": {
        "id": "6a2bb2c7"
      },
      "source": [
        "**Q5. Do your features have the same variance?**\n",
        "\n",
        "We must normalize the features. In machine learning this is called Feature Scaling\".\n",
        "We do this for the same reason we normalized prior to running the K-Means clustering algorithm.\n",
        "\n",
        "The difference here is that I will keep the data as a pandas dataframe rather than converting it to a numpy array beforehand. The \"fit_transform\" function outputs a numpy array, but we will convert back to a dataframe so that re-balancing the dataset is easier.\n",
        "\n",
        "Note: If my predictand wasn't binary, then I would also want to normalize that as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8af7b36",
      "metadata": {
        "id": "b8af7b36"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81836729",
      "metadata": {
        "id": "81836729"
      },
      "outputs": [],
      "source": [
        "def scale_data(x_train, x_test):\n",
        "    \"\"\"\n",
        "    Scale training data so that model reaches optimized weights much faster. \n",
        "    \n",
        "    *All data that enters the model should use the same scaling used to scale the training data.*\n",
        "    Thus, we also perform scaling on testing data for validation later. \n",
        "    Additionally, we return the scaler used to scale any other future input data.\n",
        "    \"\"\"\n",
        "    \n",
        "    scaler = preprocessing.MinMaxScaler() # normalize \n",
        "    x_train_scaled = pd.DataFrame(data=scaler.fit_transform(x_train),index=x_train.index,columns=x_train.columns) \n",
        "    x_test_scaled = pd.DataFrame(data=scaler.transform(x_test),index=x_test.index,columns=x_test.columns)\n",
        "    \n",
        "    return scaler, x_train_scaled, x_test_scaled"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e67f8816",
      "metadata": {
        "id": "e67f8816"
      },
      "source": [
        "**Q6. Are there the same number of observations for each outcome or class?**\n",
        "Luckily, we have the same number of observations for each feature (8784). \n",
        "\n",
        "**Question:** But do we have the same number of outcomes for our predictand - i.e., the same number of hours that are precipitating as those that are non-precipitating?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e37ad1d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e37ad1d",
        "outputId": "d7a0d1cb-db62-480f-e960-c099a252238e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    8501\n",
              "1     283\n",
              "Name: prec_occur, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "df['prec_occur'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62fce0fe",
      "metadata": {
        "id": "62fce0fe"
      },
      "source": [
        "**Answer:** Definitely not. The outcomes we are trying to predict are extremely unbalanced. Non-precip hours occur 30x more than precip hours. This class imbalance may bias the model because precip hours are underrepresented, which means the model won't have as many instances of precip hours to learn to distinguish precip hours from non-precip hours.\n",
        "\n",
        "There are a number of out-of-the-box functions that resample data very precisely. The one I use below simply randomly oversamples the existing precipitating observation data to balance the dataset.\n",
        "\n",
        "Note: This function should be called on both training and testing data separately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "920defe3",
      "metadata": {
        "id": "920defe3"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import resample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0663cc75",
      "metadata": {
        "id": "0663cc75"
      },
      "outputs": [],
      "source": [
        "def balance_data(x,y,verbose):\n",
        "    \"\"\"Resample data ensure model is not biased towards a particular outcome of precip or no precip.\"\"\"\n",
        "    # Combine again to one dataframe to ensure both the predictor and predictand are resampled from the same \n",
        "    # observations based on predictand outcomes. \n",
        "    dataset = pd.concat([x, y],axis=1)\n",
        "\n",
        "    # Separating classes\n",
        "    raining = dataset[dataset['prec_occur'] == 1]\n",
        "    not_raining = dataset[dataset['prec_occur'] == 0]\n",
        "\n",
        "    random_state = randint(0,1000)\n",
        "    oversample = resample(raining, \n",
        "                           replace=True, \n",
        "                           n_samples=len(not_raining), #set the number of samples to equal the number of the majority class\n",
        "                           random_state=random_state)\n",
        "\n",
        "    # Returning to new training set\n",
        "    oversample_dataset = pd.concat([not_raining, oversample])\n",
        "\n",
        "    # reseparate oversampled data into X and y sets\n",
        "    x_bal = oversample_dataset.drop(['prec_occur'], axis=1)\n",
        "    y_bal = oversample_dataset['prec_occur']\n",
        "\n",
        "    if verbose==True:\n",
        "        print(\"After scaling and rebalacing...\")\n",
        "        print(\"Shape of predictors: \"+str(np.shape(x_bal)))\n",
        "        print(\"Shape of predictands: \"+str(np.shape(y_bal)))\n",
        "        print(\" \")\n",
        "    \n",
        "    return x_bal, y_bal"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "597128e9",
      "metadata": {
        "id": "597128e9"
      },
      "source": [
        "**Having got this far -- Now, let's put the data prep code from questions 1-6 into a pipeline.  In other words we will write a single function to accomplish everything we have done so far in this notebook.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b4daf7b",
      "metadata": {
        "id": "3b4daf7b"
      },
      "outputs": [],
      "source": [
        "def dataprep_pipeline(x, y, verbose):\n",
        "    \"\"\" Combines all the functions defined above so that the user only has to \n",
        "    call one function to do all data pre-processing. \"\"\"\n",
        "    # verbose=True prints the shapes of input & output data\n",
        "\n",
        "    # split into training & testing data\n",
        "    x_train, x_test, y_train, y_test = define_holdout_data(x, y, verbose) \n",
        "\n",
        "    # perform feature scaling\n",
        "    scaler, x_train_scaled, x_test_scaled = scale_data(x_train, x_test)\n",
        "\n",
        "    # rebalance according to outcomes (i.e., the number of precipitating \n",
        "    # observations & non-precipitating outcomes should be equal)\n",
        "    if verbose==True:\n",
        "        print(\"for training data... \")\n",
        "    x_train_bal, y_train_bal = balance_data(x_train_scaled, y_train, verbose)\n",
        "    if verbose==True:\n",
        "        print(\"for testing data... \")\n",
        "    x_test_bal, y_test_bal = balance_data(x_test_scaled, y_test, verbose)\n",
        "    \n",
        "    return x_train_bal, y_train_bal, x_test_bal, y_test_bal"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "888e4f75",
      "metadata": {
        "id": "888e4f75"
      },
      "source": [
        "**Q7. What are the appropriate metrics for assessing your model?**\n",
        "These metrics will be used to evaluate the model after training. Thus, these functions will also be called for each model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f54cc1e3",
      "metadata": {
        "id": "f54cc1e3"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf8887a1",
      "metadata": {
        "id": "cf8887a1"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74343d78",
      "metadata": {
        "id": "74343d78"
      },
      "source": [
        "First, define functions for evaluating models\n",
        "I'm simply going to train various models and then look at their model metrics. Then we can make a prediction based on some selected observation to obtain a likelihood that it's raining, and we can compare with our own eyes whether the model gets it right.\n",
        "\n",
        "Below are some commonly-used metrics for assessing the value of a given Machine Learning model.\n",
        "\n",
        "\"**True Positive (TP)**\" Is the number of times the model predicts a positive when the observation is actually positive. In our case, the model predicts that its raining when it is actually raining.<br>\n",
        "\"**False Positive (FP)**\" The number of times the model guesses that it's raining when it's not actually raining.<br>\n",
        "The same applies to **True Negatives (TN)** (correctly predicting that it's not raining) and **False Negatives (FN)** (predicting no rain when it's actually raining).\n",
        "\n",
        "\n",
        " - **Precision = TP/(TP + FP)**: The proportion of predicted precipitating events that are actually precipitating.\n",
        " - **Accuracy = (TP + TN)/(total)**: The proportion of precipitating hours or non-precipitating hours that are correctly predicted by the model.\n",
        " - **Recall = TP/(TP + FN)**: The proportion of precipitating hours that are correctly predicted by the model.<br>\n",
        "<br>\n",
        "Other important metrics that we aren't going to look at today:\n",
        " - **F1**: a way to capture how well the model predicts the hours that it's actually precipitating.\n",
        " - **ROC/AUC**: how well the model separates precipitating hours from non-precipitating hours."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa0c1be8",
      "metadata": {
        "id": "fa0c1be8"
      },
      "outputs": [],
      "source": [
        "# Print rounded metrics for each model.\n",
        "def bin_metrics(x, y):\n",
        "    \"\"\"Prints accuracy and recall metrics for evaluating \n",
        "    classification predictions.\"\"\"\n",
        "    \n",
        "    accuracy = metrics.accuracy_score(x, y)\n",
        "    recall = metrics.recall_score(x, y)\n",
        "\n",
        "    print('Accuracy:', round(accuracy, 4))\n",
        "    print('Recall:', round(recall, 4))\n",
        "    \n",
        "    return accuracy, recall\n",
        "\n",
        "\n",
        "# Plot confusion matrix\n",
        "def plot_cm(x, y):\n",
        "    \"\"\"Plots the confusion matrix to visualize true \n",
        "    & false positives & negatives\"\"\"\n",
        "    cm = confusion_matrix(x, y)\n",
        "    df_cm = pd.DataFrame(cm, columns=np.unique(x), index = np.unique(x))\n",
        "    df_cm.index.name = 'Actual'\n",
        "    df_cm.columns.name = 'Predicted'\n",
        "    sns.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 25}, fmt='g')# font size\n",
        "    plt.ylim([0, 2])\n",
        "    plt.xticks([0.5, 1.5], ['Negatives','Positives'])\n",
        "    plt.yticks([0.5, 1.5], ['Negatives','Positives'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecb74cf5",
      "metadata": {
        "id": "ecb74cf5"
      },
      "outputs": [],
      "source": [
        "##Based on our answer to number 7 under the \"1. Data Preparation\" section above, \n",
        "##I will be using Accuracy and Recall to compare these four different models.\n",
        "\n",
        "#Another way we can evaluate the models is to compare precipitation likelihood given the same set of atmospheric conditions.\n",
        "#First, let's choose some observation in the pre-scaled dataset shows that it's raining, and then find the corresponding scaled observation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cf4f28f",
      "metadata": {
        "id": "5cf4f28f"
      },
      "outputs": [],
      "source": [
        "def rand_atmos_conditions_precip(index='rand'):\n",
        "    \"\"\"\n",
        "    Function returns atmospheric conditions in a dataframe as well as the scaled\n",
        "    conditions in a numpy array so that they output a prediction in the model.\n",
        "    \n",
        "    If no input is passed, the function will randomly generate an in index to \n",
        "    choose from those observations in some training data with precipitation. \n",
        "    Otherwise, an integer index between 0 and 200 should be passed.\n",
        "    \"\"\"\n",
        "    # First, perform a test-train split\n",
        "    x_train, x_test, y_train, _ = define_holdout_data(x, y, verbose=False) \n",
        "\n",
        "    # perform feature scaling\n",
        "    _, x_train_scaled, _ = scale_data(x_train, x_test)\n",
        "\n",
        "    # this is what will go into the model to output a prediction\n",
        "    if index=='rand':\n",
        "        index = randint(0,len(y_train[y_train==1].index)) \n",
        "    precipindex = y_train[y_train==1].index.values[index]\n",
        "    testpredictor = x_train_scaled.loc[precipindex] \n",
        "    \n",
        "    return df.iloc[precipindex], testpredictor    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac59d0ec",
      "metadata": {
        "id": "ac59d0ec"
      },
      "source": [
        "# Train & Compare four Machine Learning models\n",
        "Each section below goes through building and training a ML model. In each section, there are a few steps for each model \"pipeline\":\n",
        "1. __Randomly perform a test-train split, feature scaling, and resample data to ensure outcomes are balanced__. \n",
        "2. __Train your model__.\n",
        "3. __Assess model metrics with testing and training data__. We begin by first assessing each model's performance by calculating the metrics defined above on the *testing* or *holdout* data; the key here is that the model has never seen this data. <br>__If applicable, tune your model.__ This means choosing new *hyperparameters*, retraining the model, and then reassessing the same model metrics to see if the model yields better results.\n",
        "3. __Check for model overfitting__. We will also check to see if the model is overfitting by comparing metrics of the testing data to that of the training data. In short, the training data should not be outperforming the testing data.\n",
        "4. __Actually make a prediction with a single observation__. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec963c2d",
      "metadata": {
        "id": "ec963c2d"
      },
      "source": [
        "## Model 1: Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72d5eeb0",
      "metadata": {
        "id": "72d5eeb0"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca2129a9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca2129a9",
        "outputId": "ad36ce91-2250-4013-f7be-305699f81fbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prior to scaling and rebalacing...\n",
            "Shape of training predictors: (7027, 9)\n",
            "Shape of testing predictors: (1757, 9)\n",
            "Shape of training predictands: (7027,)\n",
            "Shape of testing predictands: (1757,)\n",
            " \n",
            "for training data... \n",
            "After scaling and rebalacing...\n",
            "Shape of predictors: (13590, 9)\n",
            "Shape of predictands: (13590,)\n",
            " \n",
            "for testing data... \n",
            "After scaling and rebalacing...\n",
            "Shape of predictors: (3412, 9)\n",
            "Shape of predictands: (3412,)\n",
            " \n"
          ]
        }
      ],
      "source": [
        "## 1. Perform a test-train split, perform feature scaling, and the rebalance our dataset.\n",
        "x_train_bal, y_train_bal, x_test_bal, y_test_bal = dataprep_pipeline(x, y, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8db8e2f0",
      "metadata": {
        "id": "8db8e2f0"
      },
      "outputs": [],
      "source": [
        "## 2. Train the Logistic Regression model\n",
        "# initialize the model\n",
        "lr = LogisticRegression(solver='lbfgs') \n",
        "# we choose this particular solver because we're not regularizing or penalizing certain features\n",
        "\n",
        "# fit the model to scaled & balanced training data. Side note: this is where *Gradient Descent* occurs.\n",
        "lr.fit(x_train_bal, y_train_bal);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7d10da1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7d10da1",
        "outputId": "c1f4d796-a2a8-48c6-f3f8-728da284530b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8312\n",
            "Recall: 0.8558\n"
          ]
        }
      ],
      "source": [
        "## 3. Assess Logistic Regression's performance using testing data\n",
        "##Now that we've \"trained\" our model, we make predictions using data that the \n",
        "## model has never seen before (i.e., our holdout testing data) to see how it performs.\n",
        "\n",
        "y_pred = lr.predict(x_test_bal)\n",
        "\n",
        "# Call functions defined above to calculate metrics & plot a confusion matrix based on\n",
        "# how well model simulates testing data\n",
        "#plot_cm(y_test_bal, y_pred);\n",
        "lr_acc, lr_rec = bin_metrics(y_test_bal, y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fad3d91b",
      "metadata": {
        "id": "fad3d91b"
      },
      "outputs": [],
      "source": [
        "## TEXT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "700f23a5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "700f23a5",
        "outputId": "2343dcb4-e719-4777-fcc0-fdc72a0a132f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training metrics:\n",
            "Accuracy: 0.8444\n",
            "Recall: 0.8756\n",
            " \n",
            "Testing metrics:\n",
            "Accuracy: 0.8312\n",
            "Recall: 0.8558\n"
          ]
        }
      ],
      "source": [
        "##4. Check to see if the Logistic Regression model is overfitting (or underfitting)\n",
        "#Remember:\n",
        "#testing metrics > training metrics = underfitting, model is too simple\n",
        "#testing metrics < training metrics = overfitting, model is too complex\n",
        "\n",
        "# Compare testing data metrics to data training metrics.\n",
        "print(\"Training metrics:\")\n",
        "pred_train= lr.predict(x_train_bal) \n",
        "bin_metrics(y_train_bal,pred_train);\n",
        "\n",
        "# As a reminder, display testing metrics:\n",
        "print(\" \")\n",
        "print(\"Testing metrics:\")\n",
        "bin_metrics(y_test_bal, y_pred);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8da5ba77",
      "metadata": {
        "id": "8da5ba77"
      },
      "outputs": [],
      "source": [
        "## 5. Make a prediction with the Logistic Regression model\n",
        "#First, we randomly choose some atmospheric conditions using the function defined above. \n",
        "#This will be the atmospheric conditions we use for all models we build.\n",
        "\n",
        "origvals, testpredictor = rand_atmos_conditions_precip()\n",
        "# print(origvals) # observation from original dataframe\n",
        "# print(testpredictor) # scaled observation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce35350c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce35350c",
        "outputId": "01f1a4ee-a758-4bf6-9847-4b5334541c78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The meteorological conditions are: \n",
            "day             2016-04-16\n",
            "hour              0.041667\n",
            "temp_F                35.0\n",
            "RH                    86.5\n",
            "dewtemp_F             31.4\n",
            "wind_mph              13.8\n",
            "wind_dir               315\n",
            "windgust              21.0\n",
            "windgust_dir           324\n",
            "pres_Hg             840.92\n",
            "SOLIN_Wm2              0.0\n",
            "Prec_inches           0.08\n",
            "prec_occur               1\n",
            "Name: 2545, dtype: object\n",
            " \n",
            "There is a 95.65% chance of precipitation given those meteorological conditions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        }
      ],
      "source": [
        "# prediction output is in the format [probability no rain, probability rain]\n",
        "lr_prediction = lr.predict_proba(np.array(testpredictor).reshape(1, -1))[0][1]*100 \n",
        "print(\"The meteorological conditions are: \")\n",
        "print(origvals)\n",
        "print(\" \")\n",
        "print(\"There is a {0:.{digits}f}% chance of precipitation given those meteorological conditions.\".format(lr_prediction, digits=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d5e0db2",
      "metadata": {
        "id": "1d5e0db2"
      },
      "source": [
        "## Model 2: Random Forest\n",
        "\n",
        "To understand random forests, one must first understand a [decision tree](https://scikit-learn.org/stable/modules/tree.html#tree). A decision tree is intuitive: it is essentially a flowchart to point to an outcome based on \"decisions\" for each feature. <br><br>\n",
        "A Random Forest is an ensemble of decision trees that are randomly constructed based on the features of the dataset and number of decisions. Trees are constructed by randomly choosing a feature to \"seed\" each tree, and then making rules or associations with other features to lead to the specified outcome."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bf08596",
      "metadata": {
        "id": "5bf08596"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3b11786",
      "metadata": {
        "id": "d3b11786"
      },
      "outputs": [],
      "source": [
        "##1. Perform a test-train split, perform feature scaling, and the rebalance our dataset.\n",
        "## Perform a train-test split for cross-validation, perform feature scaling, and \n",
        "## rebalance each testing & training dataset.\n",
        "\n",
        "x_train_bal, y_train_bal, x_test_bal, y_test_bal = dataprep_pipeline(x, y, verbose=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed28b135",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed28b135",
        "outputId": "9a50299b-a2ef-4e91-e649-65321b833887"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of estimators is 10\n",
            "depth is 2\n",
            "depth is 10\n",
            "depth is 100\n",
            "Random Forest took 0.9620890617370605 seconds.\n",
            "Number of estimators is 50\n",
            "depth is 2\n",
            "depth is 10\n",
            "depth is 100\n",
            "Random Forest took 2.517953872680664 seconds.\n",
            "Number of estimators is 500\n",
            "depth is 2\n",
            "depth is 10\n",
            "depth is 100\n",
            "Random Forest took 18.91431427001953 seconds.\n"
          ]
        }
      ],
      "source": [
        "##2. Train (and tuning) the Random Forest model\n",
        "\n",
        "##Choosing hyperparameters: There are many hyperparameters one can decide upon when \n",
        "## tuning the Random Forest classifier. The two we will be adjusting is\n",
        "##1) The number of estimators or \"trees\" in the forest\n",
        "##2) The depth of the tree, or how many \"decisions\" are made until convergence is reached.\n",
        "\n",
        "acc_scores = []\n",
        "rec_scores = []\n",
        "\n",
        "num_est = [10, 50, 500] # number of trees\n",
        "depth = [2, 10, 100] # number of decisions\n",
        "for i in num_est:\n",
        "    start = time.time()\n",
        "    print(\"Number of estimators is \"+str(i))\n",
        "\n",
        "    for k in depth:\n",
        "        print(\"depth is \"+str(k))\n",
        "        forest = RandomForestClassifier(n_estimators=i, max_depth=k)\n",
        "        forest.fit(x_train_bal, y_train_bal)\n",
        "        \n",
        "        # cross validate & evaluate metrics based on testing data\n",
        "        pred_test= forest.predict(x_test_bal)\n",
        "        acc_val = metrics.accuracy_score(y_test_bal, pred_test)\n",
        "        acc_scores.append(acc_val)\n",
        "        rec_val = metrics.recall_score(y_test_bal, pred_test)\n",
        "        rec_scores.append(rec_val)\n",
        "\n",
        "    end = time.time()\n",
        "    print(\"Random Forest took \"+str(end-start)+\" seconds.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79589936",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "79589936",
        "outputId": "067aac89-9c2d-4e07-9051-4eeecc164b8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Accuracy (black): 0.8381\n",
            "Max Recall (blue): 0.8121\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(acc_scores, marker='o', color='black')\n",
        "plt.plot(rec_scores, marker='o', color='blue')\n",
        "print(\"Max Accuracy (black):\", round(max(acc_scores), 4))\n",
        "print(\"Max Recall (blue):\", round(max(rec_scores), 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0681e6b",
      "metadata": {
        "id": "c0681e6b"
      },
      "outputs": [],
      "source": [
        "##Choosing the right hyperparameters for this model requires revisiting which \n",
        "##metrics are most important to our question. We want to maximize both recall and accuracy.\n",
        "#For simplicity, I choose the parameters corresponding to x=0, but \n",
        "#I highly suggest you try other combinations of parameters as well.\n",
        "\n",
        "forest = RandomForestClassifier(n_estimators=10, max_depth=2);\n",
        "forest.fit(x_train_bal, y_train_bal);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5280d6c2",
      "metadata": {
        "id": "5280d6c2"
      },
      "outputs": [],
      "source": [
        "forest = RandomForestClassifier(n_estimators=10, max_depth=2);\n",
        "forest.fit(x_train_bal, y_train_bal);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1ad9003",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1ad9003",
        "outputId": "3185e268-5b06-4ba0-e738-05fdf01a00f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7878\n",
            "Recall: 0.7436\n"
          ]
        }
      ],
      "source": [
        "## 3. Assess the Random Forest's performance using testing data\n",
        "##Once again, we will use our testing data to make an initial evaluation of how the model is doing.\n",
        "\n",
        "pred_test= forest.predict(x_test_bal)\n",
        "\n",
        "# Call functions defined above to calculate metrics & plot a confusion matrix based on\n",
        "# how well model simulates testing data\n",
        "forest_acc, forest_rec = bin_metrics(y_test_bal, pred_test)\n",
        "#plot_cm(y_test_bal, pred_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48eefb0b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48eefb0b",
        "outputId": "1f341ec5-ec99-473f-fa4c-0b61f66bcbf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training metrics:\n",
            "Accuracy: 0.8086\n",
            "Recall: 0.7883\n",
            " \n",
            "Testing metrics:\n",
            "Accuracy: 0.7878\n",
            "Recall: 0.7436\n"
          ]
        }
      ],
      "source": [
        "## 4. Check to see if the Random Forest is overfitting\n",
        "\n",
        "# Compare testing data metrics to data training metrics.\n",
        "print(\"Training metrics:\")\n",
        "rf_pred_train= forest.predict(x_train_bal) \n",
        "bin_metrics(y_train_bal,rf_pred_train);\n",
        "\n",
        "# As a reminder, display testing metrics:\n",
        "print(\" \")\n",
        "print(\"Testing metrics:\")\n",
        "bin_metrics(y_test_bal, pred_test);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14c811a6",
      "metadata": {
        "id": "14c811a6"
      },
      "outputs": [],
      "source": [
        "#Random forests seldom overfit, but if they do, one should try increasing the number of trees, or decreasing the amount of data used to construct each tree. See scikit-learn's Random Forest Classifier webpage for \n",
        "#information on more hyperparameters one can tune to address overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9c11a19",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9c11a19",
        "outputId": "8f6fa52b-2431-47cb-872b-9b489bac592f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The meteorological conditions are: \n",
            "day             2016-03-18\n",
            "hour                 0.125\n",
            "temp_F                21.3\n",
            "RH                    89.7\n",
            "dewtemp_F             18.8\n",
            "wind_mph              12.0\n",
            "wind_dir               322\n",
            "windgust              16.8\n",
            "windgust_dir           318\n",
            "pres_Hg             844.75\n",
            "SOLIN_Wm2              0.1\n",
            "Prec_inches           0.01\n",
            "prec_occur               1\n",
            "Name: 1851, dtype: object\n",
            " \n",
            "There is a 79.78% chance of precipitation given those meteorological conditions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        }
      ],
      "source": [
        "##5. Make a prediction with the Random Forest\n",
        "\n",
        "# prediction output is in the format [probability no rain, probability rain]\n",
        "forest_prediction = forest.predict_proba(np.array(testpredictor).reshape(1, -1))[0][1]*100 \n",
        "print(\"The meteorological conditions are: \")\n",
        "print(origvals)\n",
        "print(\" \")\n",
        "print(\"There is a {0:.{digits}f}% chance of precipitation given those meteorological conditions.\".format(forest_prediction, digits=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "133f1b1f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "133f1b1f",
        "outputId": "da6dab0c-4637-4f5a-a40f-addfc8c1c052"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    Logistic Regression  Random Forest\n",
              "Metrics                                               \n",
              "Accuracy                       0.831184       0.787763\n",
              "Recall                         0.855803       0.743560\n",
              "Prediction example            95.652761      79.784011"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1e8528a0-095c-41c8-8084-4ae03dd66a0a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Logistic Regression</th>\n",
              "      <th>Random Forest</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Metrics</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Accuracy</th>\n",
              "      <td>0.831184</td>\n",
              "      <td>0.787763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Recall</th>\n",
              "      <td>0.855803</td>\n",
              "      <td>0.743560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Prediction example</th>\n",
              "      <td>95.652761</td>\n",
              "      <td>79.784011</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e8528a0-095c-41c8-8084-4ae03dd66a0a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1e8528a0-095c-41c8-8084-4ae03dd66a0a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1e8528a0-095c-41c8-8084-4ae03dd66a0a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "model_metrics = pd.DataFrame({'Metrics':['Accuracy','Recall','Prediction example'],\n",
        "     'Logistic Regression':[lr_acc, lr_rec, lr_prediction],\n",
        "    'Random Forest':[forest_acc, forest_rec, forest_prediction]})\n",
        "model_metrics = model_metrics.set_index('Metrics')\n",
        "model_metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4f04IDpvAuNW"
      },
      "id": "4f04IDpvAuNW",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "Example_christman_supervised_ML.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}